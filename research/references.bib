@article{pokorny_new_1982,
	title = {New observations concerning red–green color defects},
	volume = {7},
	number = {2},
	journal = {Color Research \& Application},
	author = {Pokorny, Joel and Smith, Vivianne C.},
	year = {1982},
	note = {Publisher: Wiley Online Library},
	pages = {159--164},
}

@article{meyer_color_defective_1988,
	title = {Color-defective vision and computer graphics displays},
	volume = {8},
	number = {5},
	journal = {IEEE Computer Graphics and Applications},
	author = {Meyer, Gary W. and Greenberg, Donald P.},
	year = {1988},
	note = {Publisher: IEEE},
	pages = {28--40},
}

@misc{daltonize_org,
	title = {daltonize.org},
    year = {2010},
	url = {http://www.daltonize.org},
}

@misc{dietrich_daltonize_2020,
	title = {daltonize},
	author = {Dietrich, J\"org and daltonize.py},
	year = {2020},
	url = {https://github.com/joergdietrich},
}

@misc{jim_ixora_2021,
	title = {Color Blindness Simulation Research},
	author = {Jim and Ixora},
	year = {2021},
	url = {https://ixora.io/projects/colorblindness/color-blindness-simulation-research/},
}

@article{fidaner_analysis_2005,
	title = {Analysis of {Color} {Blindness}},
	author = {Fidaner, Onur and Lin, Poliang and Ozguven, Nevran},
	year = {2005},
}

@article{vienot_what_1995,
	title = {What do colour-blind people see?},
	volume = {376},
	issn = {00280836},
	doi = {10.1038/376127a0},
	abstract = {Eng LETTER},
	number = {6536},
	journal = {Nature},
	author = {Viénot, F. and Brettef, H. and Ott, L. and M’ Barek, A. Ben and Mollon, J. D.},
	year = {1995},
	pages = {127--128},
}

@article{brettel_computerized_1997,
	title = {Computerized simulation of color appearance for dichromats},
	volume = {14},
	number = {10},
	author = {Brettel, Hans and Mollon, John D},
	year = {1997},
	pages = {2647--2655},
}

@article{simon_liedtke_evaluating_2016,
	title = {Evaluating color vision deficiency daltonization methods using a behavioral visual-search method},
	volume = {35},
	issn = {10473203},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1047320315002540},
	doi = {10.1016/j.jvcir.2015.12.014},
	abstract = {Daltonization methods are used to automatically improve color images for color-deﬁcient people. A comparison of diﬀerent daltonization methods, however, is still left undone. We propose a visual-search method to evaluate daltonization methods by assessing behavioral performances of the attentional mechanism through the analysis of accuracy and response time data. Firstly, we show that the visual-search methodology can indeed be used to evaluate daltonization methods. Secondly, we argue that a combination of natural images and Ishihara images is needed to highlight diﬀerences between the daltonization methods. Our results indicate that the investigated daltonization methods can be ranked from highest to lowest as following: Firstly, the method proposed by Kotera; secondly, the method proposed by Fidaner et al.; thirdly, the method proposed by Huang et al.; and lastly the method proposed by Kuhn et al.},
	language = {en},
	urldate = {2021-04-08},
	journal = {Journal of Visual Communication and Image Representation},
	author = {Simon-Liedtke, Joschua Thomas and Farup, Ivar},
	month = feb,
	year = {2016},
	pages = {236--247},
}

@article{simon_liedtke_multiscale_2018,
	title = {Multiscale {Daltonization} in the {Gradient} {Domain}},
	volume = {1},
	issn = {2575-8144},
	url = {https://www.ingentaconnect.com/content/10.2352/J.Percept.Imaging.2018.1.1.010503},
	doi = {10.2352/J.Percept.Imaging.2018.1.1.010503},
	abstract = {We propose a daltonization method that enhances chromatic edges and contrast for color-deﬁcient people by optimizing the gradient of an image. We rotate and scale the error gradient between the original and its simulation in the color space into the direction of optimal visibility that is orthogonal to both the main direction of information loss and the direction of lightness. Then, we reintegrate the daltonized image version from the modiﬁed gradient through an iterative diffusion process. Moreover, we include multiscaling to guarantee optimal daltonization on different scales of the image. Also, we provide an interface for data attachment modules designed to maintain naturalness of memory colors like neutral colors. We evaluate and compare our proposed method to other top-performing daltonization methods in behavioral and psychometric experiments. A visual-search experiment assessing performance of the attentional mechanism of the human visual system before and after daltonization measures the greatest improvement in accuracy for our proposed method compared to the original and all investigated daltonization methods. It also reveals optimal results for both natural and Ishihara images among both protan and deutan color-deﬁcient observers. Furthermore, we can deduce from the results of a pairwise preference evaluation that our proposed method is preferred highest amongst all color-deﬁcient people in total. Our proposed method is also ranked among the most preferred daltonization methods for both protan and deutan color-deﬁcient observers individually. c 2018 Society for Imaging Science and Technology.},
	language = {en},
	number = {1},
	urldate = {2021-04-08},
	journal = {Journal of Perceptual Imaging},
	author = {Simon-Liedtke, Joschua Thomas and Farup, Ivar},
	month = jan,
	year = {2018},
	pages = {10503--1--10503--12},
}

@incollection{vienot_colorimetry_2013,
	address = {Hoboken, NJ USA},
	title = {Colorimetry and {Physiology} - {The} {LMS} {Specification}},
	isbn = {978-1-118-56268-0 978-1-84821-346-3},
	url = {http://doi.wiley.com/10.1002/9781118562680.ch1},
	language = {en},
	urldate = {2021-04-10},
	booktitle = {Digital {Color}},
	publisher = {John Wiley \& Sons, Inc.},
	author = {Viénot, Françoise and Le Rohellec, Jean},
	month = mar,
	year = {2013},
	doi = {10.1002/9781118562680.ch1},
	pages = {1--28},
}

@article{simon_liedtke_using_2016,
	title = {Using a {Behavioral} {Match}-to-{Sample} {Method} to {Evaluate} {Color} {Vision} {Deficiency} {Simulation} {Methods}},
	volume = {60},
	issn = {1062-3701},
	url = {http://www.ingentaconnect.com/content/10.2352/J.ImagingSci.Technol.2016.60.5.050409},
	doi = {10.2352/J.ImagingSci.Technol.2016.60.5.050409},
	abstract = {Color vision deﬁciency (CVD) simulation methods are used both to simulate color vision of color-deﬁcient people and as input for image enhancement methods for the color-deﬁcient. However, a standardized method to compare simulation methods has not yet been deﬁned. We propose a behavioral methodology to evaluate, compare and rank different simulation methods. By using accuracy and response time data from a match-to-sample experiment, we can assess behavioral performance of simulation methods. We show ﬁrstly that the match-to-sample paradigm is well suited to show performance differences between observer groups; secondly, that the simulation methods do indeed simulate the desired CVD to some degree; and thirdly, we show that the proposed methodology can be used to rank different simulation methods. Our results indicate that the simulation method proposed by Brettel et al. depicts deutan CVD more accurately than the simulation method proposed by Kotera. c 2016 Society for Imaging Science and Technology.},
	language = {en},
	number = {5},
	urldate = {2021-04-10},
	journal = {Journal of Imaging Science and Technology},
	author = {Simon-Liedtke, Joschua Thomas and Farup, Ivar},
	month = sep,
	year = {2016},
	pages = {504091--504099},
}

@incollection{smith_color_2003,
	title = {Color {Matching} and {Color} {Discrimination}},
	isbn = {978-0-444-51251-2},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780444512512500040},
	language = {en},
	urldate = {2021-04-18},
	booktitle = {The {Science} of {Color}},
	publisher = {Elsevier},
	author = {Smith, Vivianne C. and Pokorny, Joel},
	year = {2003},
	doi = {10.1016/B978-044451251-2/50004-0},
	pages = {103--148},
}

@article{vienot_digital_1999,
	title = {Digital video colourmaps for checking the legibility of displays by dichromats},
	volume = {24},
	number = {4},
	journal = {Color Research \& Application},
	author = {Viénot, Françoise and Brettel, Hans and Mollon, John D.},
	year = {1999},
	note = {Publisher: Wiley Online Library},
	pages = {243--252},
}

@article{smith_spectral_1975,
	title = {Spectral sensitivity of the foveal cone photopigments between 400 and 500 nm},
	volume = {15},
	number = {2},
	journal = {Vision research},
	author = {Smith, Vivianne C. and Pokorny, Joel},
	year = {1975},
	note = {Publisher: Elsevier},
	pages = {161--171},
}

@inproceedings{kotera_optimal_2012,
	title = {Optimal daltonization by spectral shift for dichromatic vision},
	volume = {2012},
	booktitle = {Color and {Imaging} {Conference}},
	publisher = {Society for Imaging Science and Technology},
	author = {Kotera, Hiroaki},
	year = {2012},
	note = {Issue: 1},
	pages = {302--308},
}

@article{smith_chromatic-discrimination_1995,
	title = {Chromatic-discrimination axes, {CRT} phosphor spectra, and individual variation in color vision},
	volume = {12},
	number = {1},
	journal = {JOSA A},
	author = {Smith, Vivianne C. and Pokorny, Joel},
	year = {1995},
	note = {Publisher: Optical Society of America},
	pages = {27--35},
}

@inproceedings{vienot_color_2000,
	title = {Color display for dichromats},
	volume = {4300},
	booktitle = {Color {Imaging}: {Device}-{Independent} {Color}, {Color} {Hardcopy}, and {Graphic} {Arts} {VI}},
	publisher = {International Society for Optics and Photonics},
	author = {Viénot, Françoise and Brettel, Hans},
	year = {2000},
	pages = {199--207},	
}

@article{woods_modifying_2005,
	title = {Modifying images for color blind viewers},
	journal = {Electrical Engineering Department Stanford University Stanford, USA wwwoods@ stanford. edu},
	author = {Woods, William},
	year = {2005},
}

@article{machado_physiologically_based_2009,
	title = {A physiologically-based model for simulation of color vision deficiency},
	volume = {15},
	issn = {10772626},
	doi = {10.1109/TVCG.2009.113},
	abstract = {Color vision deficiency (CVD) affects approximately 200 million people worldwide, compromising the ability of these individuals to effectively perform color and visualization-related tasks. This has a significant impact on their private and professional lives. We present a physiologically-based model for simulating color vision. Our model is based on the stage theory of human color vision and is derived from data reported in electrophysiological studies. It is the first model to consistently handle normal color vision, anomalous trichromacy, and dichromacy in a unified way. We have validated the proposed model through an experimental evaluation involving groups of color vision deficient individuals and normal color vision ones. Our model can provide insights and feedback on how to improve visualization experiences for individuals with CVD. It also provides a framework for testing hypotheses about some aspects of the retinal photoreceptors in color vision deficient individuals.},
	number = {6},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Machado, Gustavo M. and Oliveira, Manuel M. and Fernandes, Leandro A.F.},
	year = {2009},
	keywords = {Anomalous Trichromacy, Color Perception, Dichromacy, Models of Color Vision, Simulation of Color Vision Deficiency},
	pages = {1291--1298},
}

@article{hunt_reproduction_2004,
	title = {The {Reproduction} of {Colour}},
	language = {en},
	author = {Hunt, R W G},
	year = {2004},
	keywords = {★},
	pages = {726},
}

@article{stockman_spectral_2000,
	title = {The spectral sensitivities of the middle-and long-wavelength-sensitive cones derived from measurements in observers of known genotype},
	volume = {40},
	journal = {Vision Research},
	author = {Stockman, Andrew and Sharpe, Lindsay T.},
	year = {2000},
	keywords = {★},
	pages = {1711--1737},
}

@article{estevez1981fundamental,
  title={On the fundamental data-base of normal and dichromatic colour vision},
  author={Est{\'e}vez, O},
  journal={Ph. D. Thesis, University of Amsterdam},
  year={1981}
}


@article{macalpine_real_time_2016,
	title = {Real-{Time} {Mobile} {Personalized} {Simulations} of {Impaired} {Colour} {Vision}},
	abstract = {Colour forms an essential element of day-to-day life for most people, but at least 5\% of the world have Impaired Colour Vision (ICV) – seeing fewer colours than everyone else. Those with typical colour vision ﬁnd it diﬃcult to understand how people with ICV perceive colour, leading to misunderstand­ ing and challenges for people with ICV. To help improve understanding, personalized simulations of ICV have been developed, but are computationally demanding (so limited to static images), which limits the value of these simulations. To address this, we extended personalized ICV simulations to work in real time on a mobile device to allow people with typical colour vision greater freedom in exploring ICV. To validate our approach, we compared our real-time simulation technique to an existing adjustable simulation technique and found general agreement between the two. We then deployed three real-time personalized ICV simulations to nine people with typical colour vision, encouraging them to take pho­ tos of interesting colour situations. In just over one week, participants recorded over 450 real-world images of situa­ tions where their simulation presented a distinct challenge for their respective ICV participant. Through a question­ naire and discussion of photos with participants, we found that our solution provides a valuable mechanism for building understanding of ICV for people with typical colour vision.},
	language = {en},
	author = {MacAlpine, Rhouri and Flatla, David R},
	year = {2016},
	keywords = {★},
	pages = {9},
	file = {MacAlpine and Flatla - Real-Time Mobile Personalized Simulations of Impai.pdf:/home/nb/Zotero/storage/E35CSAJD/MacAlpine and Flatla - Real-Time Mobile Personalized Simulations of Impai.pdf:application/pdf},
}

@inproceedings{flatla_so_2012,
	address = {New York, NY, USA},
	series = {{ASSETS} '12},
	title = {"{So} that's what you see": building understanding with personalized simulations of colour vision deficiency},
	isbn = {978-1-4503-1321-6},
	shorttitle = {"{So} that's what you see"},
	url = {https://doi.org/10.1145/2384916.2384946},
	doi = {10.1145/2384916.2384946},
	abstract = {Colour vision deficiencies (CVD) affect the everyday lives of a large number of people, but it is difficult for others - even friends and family members - to understand the experience of having CVD. Simulation tools can help provide this experience; however, current simulations are based on general models that have several limitations, and therefore cannot accurately reflect the perceptual capabilities of most individuals with reduced colour vision. To address this problem, we have developed a new simulation approach that is based on a specific empirical model of the actual colour perception abilities of a person with CVD. The resulting simulation is therefore a more exact representation of what a particular person with CVD actually sees. We tested the new approach in two ways. First, we compared its accuracy with that of the existing models, and found that the personalized simulations were significantly more accurate than the old method. Second, we asked pairs of participants (one with CVD, and one close friend or family member without CVD) to discuss images of everyday scenes that had been simulated with the CVD person's particular model. We found that the personalized simulations provided new insights into the details of the CVD person's experience. The personalized-simulation approach shows great promise for improving understanding of CVD (and potentially other conditions) for people with ordinary perceptual abilities.},
	urldate = {2021-04-27},
	booktitle = {Proceedings of the 14th international {ACM} {SIGACCESS} conference on {Computers} and accessibility},
	publisher = {Association for Computing Machinery},
	author = {Flatla, David R. and Gutwin, Carl},
	month = oct,
	year = {2012},
	keywords = {★, colour vision deficiency, colour vision simulation},
	pages = {167--174},
	file = {Citeseer - Full Text PDF:/home/nb/Zotero/storage/FDGI26LP/Flatla and Gutwin - “So Thatʼs What You See! ” Building Understanding .pdf:application/pdf},
}

@book{fairchild2013color,
  title={Color appearance models},
  author={Fairchild, Mark D},
  year={2013},
  publisher={John Wiley \& Sons}
}

@article{capilla_corresponding_pair_2004,
	title = {Corresponding-pair procedure: a new approach to simulation of dichromatic color perception},
	volume = {21},
	issn = {1084-7529},
	shorttitle = {Corresponding-pair procedure},
	doi = {10.1364/josaa.21.000176},
	abstract = {The dichromatic color appearance of a chromatic stimulus T can be described if a stimulus S is found that verifies that a normal observer experiences the same sensation viewing S as a dichromat viewing T. If dichromatic and normal versions of the same color vision model are available, S can be computed by applying the inverse of the normal model to the descriptors of T obtained with the dichromatic model. We give analytical form to this algorithm, which we call the corresponding-pair procedure. The analytical form highlights the requisites that a color vision model must verify for this procedure to be used. To show the capabilities of the method, we apply the algorithm to different color vision models that verify such requisites. This algorithm avoids the need to introduce empirical information alien to the color model used, as was the case with previous methods. The relative simplicity of the procedure and its generality makes the prediction of dichromatic color appearance an additional test of the validity of color vision models.},
	language = {eng},
	number = {2},
	journal = {Journal of the Optical Society of America. A, Optics, Image Science, and Vision},
	author = {Capilla, Pascual and Díez-Ajenjo, María Amparo and Luque, María José and Malo, Jesús},
	month = feb,
	year = {2004},
	pmid = {14763760},
	keywords = {★},
	pages = {176--186},
	file = {Capilla et al. - 2004 - Corresponding-pair procedure a new approach to si.pdf:/home/nb/Zotero/storage/I8YGWJYL/Capilla et al. - 2004 - Corresponding-pair procedure a new approach to si.pdf:application/pdf},
}
